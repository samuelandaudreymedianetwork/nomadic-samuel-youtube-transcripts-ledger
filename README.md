# Nomadic Samuel YouTube Transcripts (Curated, EN — Full Transcripts Only)

A per-video dataset of **creator-authored transcripts / caption exports** for the **Nomadic Samuel** YouTube channel.

This release is **curated**: it only includes videos listed in `nomadic-samuel-list.csv` (included in this repository).

This **master** build contains **only videos with full transcripts** — any curated entries without a matching SRT file were excluded entirely (no placeholder rows).

## What’s inside

- **143** video records (curated list, full transcripts only)
- Output formats:
  - `data/nomadic-samuel-youtube-transcripts.jsonl` (full fidelity, includes `srt`)
  - `data/nomadic-samuel-youtube-transcripts.jsonl.gz`
  - `data/nomadic-samuel-youtube-transcripts.csv` (lite; omits `srt` + `text_with_breaks` for easier spreadsheet use)
  - `data/nomadic-samuel-youtube-transcripts.csv.gz`

## Recommended format

Use **JSONL** as the canonical source:
- Includes raw **SRT timestamps**
- Preserves full text + metadata in a single record per video

CSV is intended for quick browsing/analysis.

## Record schema (high-level)

Each JSONL line is one video record with fields including:
- Video metadata: `video_id`, `url`, `published_at`, `video_date`, `title`, `view_count`, `tags`
- Text fields: `text`, `text_with_breaks`, `srt`
- Provenance: `source`, `channel`, `caption_source`, `original_filename`
- Integrity: `content_hash` (SHA1 of `text`)

See `DATA_DICTIONARY.md` and `SCHEMA.json` for the full specification.

## Loading examples

### Python (datasets)

```python
from datasets import load_dataset

ds = load_dataset("samuelandaudreymedianetwork/nomadic-samuel-youtube-transcripts", data_files="data/nomadic-samuel-youtube-transcripts.jsonl")["train"]
print(ds[0]["title"])
print(ds[0]["text"][:200])
```

### Python (jsonlines)

```python
import json

with open("data/nomadic-samuel-youtube-transcripts.jsonl", "r", encoding="utf-8") as f:
    for line in f:
        rec = json.loads(line)
        break
```

## Notes on transcript polishing

This dataset preserves the **raw SRT** content in the `srt` field.
Derived `text` is generated by concatenating SRT caption lines and applying **minimal punctuation-spacing normalization** (e.g., removing a space before `?`).

No transcript blocks were removed. No timestamps were altered.

## License

CC BY-NC 4.0 (cc-by-nc-4.0)

## Hugging Face

https://huggingface.co/datasets/samuelandaudreymedianetwork/nomadic-samuel-youtube-transcripts
